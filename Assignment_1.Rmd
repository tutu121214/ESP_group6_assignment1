#Q1-Q3
#setwd("D:/Users/tt/SDS-Sem1/Statistical Programming/Assignment")
a <- scan("4300-0.txt",what="character",skip=73,nlines=32858-73,fileEncoding="UTF-8")
a <- gsub("_(","",a,fixed=TRUE) ## remove "_("
a

#define the split_punct function:(Q4)
##marks_position = grep(marks,words,fixed=TRUE)
split_punct <- function(words, marks){

  full_list <- words
  
  for(punc in marks){#Iterate over each element in marks
    full_list_tmp <- full_list
    matches_order <- grep(punc, full_list_tmp, fixed = TRUE)#Find the character position of the corresponding punctuation mark
    marks_len <- length(matches_order)#Number of words with corresponding punctuation marks
    full_list <- rep("",length(full_list_tmp)+marks_len)#Create an empty list that can drop both split words and punctuation.
    f <- matches_order+1:length(matches_order)#f is an indexed list of the original punctuation one position back (where the split punctuation is to be placed)
    full_list[f] <- punc
    full_list[-f] <- gsub(punc,"",full_list_tmp,fixed = TRUE)
  }
  return(full_list)
}

#Q5:Use the function to seperate the punctuation marks from words they are attached to in the text.
marks <- c(".",",",";","!",":","?")
split_punct(a, marks)

#Q6a
a_split <- split_punct(a, marks)
a_lower <- tolower(a_split)
a_lower

a_unique <- unique(a_lower)
a_unique#找到列表中只出现了一次的单词

#Q6b
index_vector <- match(a_lower, a_unique)
index_vector

occur_counts <- tabulate(index_vector)#每个符号/单词在整个文本中出现了多少次
occur_counts

#Q6d
threshold_search <- function(counts, desired_count) {
  sorted_counts <- sort(counts, decreasing = TRUE)
  return(sorted_counts[desired_count])
}

threshold <- threshold_search(occur_counts, 1000)
threshold#出现次数最多的第1000个单词的词频

#Q6e
common_words <- a_unique[occur_counts >= threshold]
##occur_counts中词频大于threshold的位置，返回该位置对应的a_unique中的单词（最常出现的1000个单词）
common_words

#Q7a
a_lower_2 <- match(a_lower, common_words)
a_lower_2

#Q7b
mlag <- 4
n <- length(a_lower)
M <- matrix(NA, n - mlag, mlag+1)

for(i in 1:(mlag+1)){
  M[,i] <- a_lower_2[i:(n-mlag+i-1)]
}
M